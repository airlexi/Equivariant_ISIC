{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import math\n",
    "import e2cnn.nn as enn\n",
    "from e2cnn.nn import init\n",
    "from e2cnn import gspaces\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import albumentations as A\n",
    "import torchtoolbox.transform as transforms\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import sklearn\n",
    "from tqdm.autonotebook import tqdm\n",
    "import isic_train\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def predict(model, batch_size):\n",
    "    \"\"\"function to predict test samples with test time augmentation \"\"\"\n",
    "    #loading the dataset\n",
    "    test_set = isic_train.MelanomaDataset(df=test_df,\n",
    "                       imfolder='test', \n",
    "                       train=False,\n",
    "                       transforms=train_transform,\n",
    "                       meta_features=meta_features)\n",
    "    \n",
    "    #initializing the dataloader\n",
    "    test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    length_dataset = len(test_set)\n",
    "    \n",
    "    #number of test time augmentation\n",
    "    number_of_tta = 5\n",
    "    \n",
    "    #setting model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    #initializing the variable for test predictions\n",
    "    test_preds = torch.zeros(size = (length_dataset, 1), device=\"cpu\", dtype=torch.float32)\n",
    "    \n",
    "    for _ in range(number_of_tta):\n",
    "        with torch.no_grad():\n",
    "            for k, (images) in tqdm(enumerate(test_loader), total=int(torch.ceil(torch.tensor(length_dataset / batch_size)).item())):\n",
    "\n",
    "                images[0] = images[0].to(device)\n",
    "                images[1] = images[1].to(device)\n",
    "\n",
    "                out = model(images)\n",
    "                pred = torch.sigmoid(out)\n",
    "                \n",
    "                #writing the predictions to the corresponding variable\n",
    "                test_preds[test_loader.batch_size*k : k*test_loader.batch_size+ images[0].shape[0]] += pred.cpu()\n",
    "\n",
    "    final_pred = test_preds/number_of_tta\n",
    "    return final_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the .csv files with meta_data\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "# data augmentation for test time augmentation\n",
    "# make sure you use the same augmentations you used in training\n",
    "test_transform = transforms.Compose([\n",
    "    isic_train.AdvancedHairAugmentation(hairs_folder='mel_hairs'),\n",
    "    transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomAffine(degrees=0, scale=(0.8,1.2), shear=(-20,20)),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "    isic_train.Microscope(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# preprocessing of meta data, taken from https://www.kaggle.com/nroman/melanoma-pytorch-starter-efficientnet\n",
    "# One-hot encoding of location of imaged site\n",
    "concat = pd.concat([train_df['anatom_site_general_challenge'], test_df['anatom_site_general_challenge']], ignore_index=True)\n",
    "dummies = pd.get_dummies(concat, dummy_na=True, dtype=np.uint8, prefix='site')\n",
    "train_df = pd.concat([train_df, dummies.iloc[:train_df.shape[0]]], axis=1)\n",
    "test_df = pd.concat([test_df, dummies.iloc[train_df.shape[0]:].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# encoding the sex of patients, -1 if it is missing\n",
    "train_df['sex'] = train_df['sex'].map({'male': 1, 'female': 0})\n",
    "test_df['sex'] = test_df['sex'].map({'male': 1, 'female': 0})\n",
    "train_df['sex'] = train_df['sex'].fillna(-1)\n",
    "test_df['sex'] = test_df['sex'].fillna(-1)\n",
    "\n",
    "# normalizing the age of the patients between 0 and 1 to use it for classification as well, 0 if the age is missing\n",
    "train_df['age_approx'] /= train_df['age_approx'].max()\n",
    "test_df['age_approx'] /= test_df['age_approx'].max()\n",
    "train_df['age_approx'] = train_df['age_approx'].fillna(0)\n",
    "test_df['age_approx'] = test_df['age_approx'].fillna(0)\n",
    "\n",
    "# filling missing values for patient_ids\n",
    "train_df['patient_id'] = train_df['patient_id'].fillna(0)\n",
    "meta_features = ['sex', 'age_approx'] + [col for col in train_df.columns if 'site_' in col]\n",
    "meta_features.remove('anatom_site_general_challenge')\n",
    "\n",
    "\n",
    "#initialize the model you want to make your submission with and load the weights and predict the test samples\n",
    "#first fold\n",
    "model = isic_train.DenseNet(32, [6,12,24,16], len(meta_features)).to(device)\n",
    "weights = torch.load(\"best_model_fold_1\")\n",
    "model.load_state_dict(weights, strict=True)\n",
    "prediction_fold_1 = predict(model, 256)\n",
    "\n",
    "#second fold\n",
    "model = isic_train.DenseNet(32, [6,12,24,16], len(meta_features)).to(device)\n",
    "weights = torch.load(\"best_model_fold_2\")\n",
    "model.load_state_dict(weights, strict=True)\n",
    "prediction_fold_2 = predict(model, 256)\n",
    "\n",
    "#third fold\n",
    "model = isic_train.DenseNet(32, [6,12,24,16], len(meta_features)).to(device)\n",
    "weights = torch.load(\"best_model_fold_3\")\n",
    "model.load_state_dict(weights, strict=True)\n",
    "prediction_fold_3 = predict(model, 256)\n",
    "\n",
    "#fourth fold\n",
    "model = isic_train.DenseNet(32, [6,12,24,16], len(meta_features)).to(device)\n",
    "weights = torch.load(\"best_model_fold_4\")\n",
    "model.load_state_dict(weights, strict=True)\n",
    "prediction_fold_4 = predict(model, 256)\n",
    "\n",
    "#fifth fold\n",
    "model = isic_train.DenseNet(32, [6,12,24,16], len(meta_features)).to(device)\n",
    "weights = torch.load(\"best_model_fold_5\")\n",
    "model.load_state_dict(weights, strict=True)\n",
    "prediction_fold_5 = predict(model, 256)\n",
    "\n",
    "#summing up the predictions of each fold and averaging them\n",
    "final_prediction = (prediction_fold_1 + prediction_fold_2 + prediction_fold_3 + prediction_fold_4 + prediction_fold_5)/5\n",
    "\n",
    "#writing the final_predictions to the submission.csv file\n",
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sub['target'] = final_prediction.cpu().numpy().reshape(-1,)\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
